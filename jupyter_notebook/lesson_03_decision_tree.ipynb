{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz: Implementing a Decision Tree\n",
    "# prep_terrain_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import random\n",
    "\n",
    "\n",
    "def makeTerrainData(n_points=1000):\n",
    "###############################################################################\n",
    "### make the toy dataset\n",
    "    random.seed(42)\n",
    "    grade = [random.random() for ii in range(0,n_points)]\n",
    "    bumpy = [random.random() for ii in range(0,n_points)]\n",
    "    error = [random.random() for ii in range(0,n_points)]\n",
    "    y = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]\n",
    "    for ii in range(0, len(y)):\n",
    "        if grade[ii]>0.8 or bumpy[ii]>0.8:\n",
    "            y[ii] = 1.0\n",
    "\n",
    "### split into train/test sets\n",
    "    X = [[gg, ss] for gg, ss in zip(grade, bumpy)]\n",
    "    split = int(0.75*n_points)\n",
    "    X_train = X[0:split]\n",
    "    X_test  = X[split:]\n",
    "    y_train = y[0:split]\n",
    "    y_test  = y[split:]\n",
    "\n",
    "    grade_sig = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
    "    bumpy_sig = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
    "    grade_bkg = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
    "    bumpy_bkg = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
    "\n",
    "#    training_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
    "#            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
    "\n",
    "\n",
    "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "\n",
    "    test_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
    "            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "#    return training_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class_vis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "#from udacityplots import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def prettyPicture(clf, X_test, y_test):\n",
    "    x_min = 0.0; x_max = 1.0\n",
    "    y_min = 0.0; y_max = 1.0\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    h = .01  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=pl.cm.seismic)\n",
    "\n",
    "    # Plot also the test points\n",
    "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "\n",
    "    plt.scatter(grade_sig, bumpy_sig, color = \"b\", label=\"fast\")\n",
    "    plt.scatter(grade_bkg, bumpy_bkg, color = \"r\", label=\"slow\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"bumpiness\")\n",
    "    plt.ylabel(\"grade\")\n",
    "\n",
    "    plt.savefig(\"test.png\")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClassifyDT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(features_train, labels_train):\n",
    "    \n",
    "    ### your code goes here--should return a trained decision tree classifer\n",
    "    from sklearn import tree\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(features_train, labels_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# studentMain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndCgqABRFUToUFQCKoigdyv8HIhFFghOz1HQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d4fdc9dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" lecture and example code for decision tree unit \"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "\n",
    "### the classify() function in classifyDT is where the magic\n",
    "### happens--fill in this function in the file 'classifyDT.py'!\n",
    "clf = classify(features_train, labels_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### grader code, do not modify below this line\n",
    "\n",
    "prettyPicture(clf, features_test, labels_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz: [object Object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.912\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "########################## DECISION TREE #################################\n",
    "\n",
    "\n",
    "\n",
    "#### your code goes here\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "### be sure to compute the accuracy on the test set\n",
    "\n",
    "\n",
    "    \n",
    "def submitAccuracies():\n",
    "  return {\"acc\":round(acc,3)}\n",
    "\n",
    "print ('The accuracy is: %.3f' % acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz: Decision Tree Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for acc_min_samples_split_2 is: 0.908\n",
      "The accuracy for acc_min_samples_split_50 is: 0.912\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "\n",
    "########################## DECISION TREE #################################\n",
    "\n",
    "\n",
    "### your code goes here--now create 2 decision tree classifiers,\n",
    "### one with min_samples_split=2 and one with min_samples_split=50\n",
    "### compute the accuracies on the testing data and store\n",
    "### the accuracy numbers to acc_min_samples_split_2 and\n",
    "### acc_min_samples_split_50, respectively\n",
    "\n",
    "def classify(features_train, labels_train):\n",
    "\n",
    "    ### your code goes here--should return a trained decision tree classifer\n",
    "    from sklearn import tree\n",
    "    clf1 = tree.DecisionTreeClassifier(min_samples_split = 2)\n",
    "    clf1 = clf1.fit(features_train, labels_train)\n",
    "    clf2 = tree.DecisionTreeClassifier(min_samples_split = 50)\n",
    "    clf2 = clf2.fit(features_train, labels_train)\n",
    "    \n",
    "\n",
    "    return [clf1, clf2]\n",
    "    \n",
    "\n",
    "clf = classify(features_train, labels_train)\n",
    "\n",
    "pred1 = clf[0].predict(features_test)\n",
    "pred2 = clf[1].predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_min_samples_split_2 = accuracy_score(labels_test, pred1)\n",
    "acc_min_samples_split_50 = accuracy_score(labels_test, pred2)\n",
    "\n",
    "\n",
    "def submitAccuracies():\n",
    "  return {\"acc_min_samples_split_2\":round(acc_min_samples_split_2,3),\n",
    "          \"acc_min_samples_split_50\":round(acc_min_samples_split_50,3)}\n",
    "\n",
    "print ('The accuracy for acc_min_samples_split_2 is: %.3f' % acc_min_samples_split_2)\n",
    "print ('The accuracy for acc_min_samples_split_50 is: %.3f' % acc_min_samples_split_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# email_preproccess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import pickle\n",
    "import cPickle\n",
    "import numpy\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(words_file = \"../ud120-projects/tools/word_data.pkl\", authors_file=\"../ud120-projects/tools/email_authors.pkl\"):\n",
    "    \"\"\" \n",
    "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
    "        and the corresponding authors (by default email_authors.pkl) and performs\n",
    "        a number of preprocessing steps:\n",
    "            -- splits into training/testing sets (10% testing)\n",
    "            -- vectorizes into tfidf matrix\n",
    "            -- selects/keeps most helpful features\n",
    "\n",
    "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
    "\n",
    "        4 objects are returned:\n",
    "            -- training/testing features\n",
    "            -- training/testing labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### the words (features) and authors (labels), already largely preprocessed\n",
    "    ### this preprocessing will be repeated in the text learning mini-project\n",
    "    authors_file_handler = open(authors_file, \"r\")\n",
    "    authors = pickle.load(authors_file_handler)\n",
    "    authors_file_handler.close()\n",
    "\n",
    "    words_file_handler = open(words_file, \"r\")\n",
    "    word_data = cPickle.load(words_file_handler)\n",
    "    words_file_handler.close()\n",
    "\n",
    "    ### test_size is the percentage of events assigned to the test set\n",
    "    ### (remainder go into training)\n",
    "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "    ### text vectorization--go from strings to lists of numbers\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "    features_test_transformed  = vectorizer.transform(features_test)\n",
    "\n",
    "\n",
    "\n",
    "    ### feature selection, because text is super high dimensional and \n",
    "    ### can be really computationally chewy as a result\n",
    "    selector = SelectPercentile(f_classif, percentile=10)\n",
    "    selector.fit(features_train_transformed, labels_train)\n",
    "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "\n",
    "    ### info on the data\n",
    "    print \"no. of Chris training emails:\", sum(labels_train)\n",
    "    print \"no. of Sara training emails:\", len(labels_train)-sum(labels_train)\n",
    "    \n",
    "    return features_train_transformed, features_test_transformed, labels_train, labels_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dt_author_id.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "The accuracy is: 0.98\n",
      "The number of features is: 3785\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\"\n",
    "    This is the code to accompany the Lesson 3 (decision tree) mini-project.\n",
    "\n",
    "    Use a Decision Tree to identify emails from the Enron corpus by author:\n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "def classify(features_train, labels_train):\n",
    "\n",
    "    from sklearn import tree\n",
    "    clf = tree.DecisionTreeClassifier(min_samples_split = 40)\n",
    "    clf = clf.fit(features_train, labels_train)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "clf = classify(features_train, labels_train)\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print ''\n",
    "print ('The accuracy is: %.2f' % acc)\n",
    "\n",
    "print ('The number of features is: %i' % len(features_train[0]))\n",
    "#########################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The fit time is: 79.30 s\n",
      "The training time is: 6.19 s\n",
      "The accuracy is: 96.42\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 3785 and input n_features is 2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a99dbafaf145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mprettyPicture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-802a4f588ca1>\u001b[0m in \u001b[0;36mprettyPicture\u001b[1;34m(clf, X_test, y_test)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.01\u001b[0m  \u001b[1;31m# step size in the mesh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Put the result into a color plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/collumbus/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \"\"\"\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/collumbus/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    401\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 3785 and input n_features is 2 "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def classify(features_train, labels_train, features_test, labels_test):\n",
    "    \"\"\" compute the accuracy of your SVM classifier \"\"\"\n",
    "    ### import the sklearn module for SVM\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "    #features_train = features_train[:len(features_train)/100]\n",
    "    #labels_train = labels_train[:len(labels_train)/100]\n",
    "\n",
    "    clf = SVC(kernel=\"rbf\", C=1e8)\n",
    "    t0 = time()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    fit_t = round(time()-t0, 3)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(features_test)\n",
    "    pred_t = round(time()-t0, 3)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = (accuracy_score(pred, labels_test))*100\n",
    "    return [fit_t, pred_t, acc, pred]\n",
    "\n",
    "print ''\n",
    "results = classify(features_train, labels_train, features_test, labels_test)\n",
    "print ('The fit time is: %.2f s' % results[0])\n",
    "print ('The training time is: %.2f s' % results[1])\n",
    "print ('The accuracy is: %.2f' % results[2])\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
