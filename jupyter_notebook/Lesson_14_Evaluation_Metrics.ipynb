{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate_poi_identifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy is: 0.7241\n",
      "[[21  4]\n",
      " [ 4  0]]\n",
      "There are 4 POIs.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Starter code for the evaluation mini-project.\n",
    "    Start by copying your trained/tested POI identifier from\n",
    "    that which you built in the validation mini-project.\n",
    "\n",
    "    This is the second step toward building your POI identifier!\n",
    "\n",
    "    Start by loading/formatting the data...\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../ud120-projects/tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "data_dict = pickle.load(open(\"../ud120-projects/final_project/final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "### add more features to features_list!\n",
    "features_list = [\"poi\", \"salary\"]\n",
    "\n",
    "data = featureFormat(data_dict, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "sort_keys = '../ud120-projects/tools/python2_lesson14_keys.pkl'\n",
    "\n",
    "### your code goes here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features,\n",
    "labels,test_size=0.3,random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "print (' The accuracy is: %.4f' % (accuracy_score(labels_test,pred)))\n",
    "print (confusion_matrix(labels_test, pred))\n",
    "print ('There are %i POIs.' % len([e for e in labels_test if e == 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 people in test set.\n"
     ]
    }
   ],
   "source": [
    "print ('There are %i people in test set.' %len(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy would be 0.862\n"
     ]
    }
   ],
   "source": [
    "print ('The accuracy would be %.3f' % ((29.-4.)/(29.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By confusion matrix we can see that there are any true positive.\n"
     ]
    }
   ],
   "source": [
    "print 'By confusion matrix we can see that there are any true positive.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The precision is: 0.0000\n",
      " The recall is: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print (' The precision is: %.4f' % (precision_score(labels_test,pred)))\n",
    "\n",
    "print (' The recall is: %.4f' % (recall_score(labels_test,pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 true positives.\n"
     ]
    }
   ],
   "source": [
    "predictions = [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n",
    "true_labels = [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]\n",
    "\n",
    "tp = 0\n",
    "for p,t in zip(predictions,true_labels):\n",
    "    if (p == 1) and (t==1):\n",
    "        tp += 1\n",
    "\n",
    "print ('There are %i true positives.' % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 true negatives.\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "for p,t in zip(predictions,true_labels):\n",
    "    if (p == 0) and (t==0):\n",
    "        tp += 1\n",
    "\n",
    "print ('There are %i true negatives.' % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 false positives.\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "for p,t in zip(predictions,true_labels):\n",
    "    if (p == 1) and (t==0):\n",
    "        tp += 1\n",
    "\n",
    "print ('There are %i false positives.' % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 false negatives.\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "for p,t in zip(predictions,true_labels):\n",
    "    if (p == 0) and (t==1):\n",
    "        tp += 1\n",
    "\n",
    "print ('There are %i false negatives.' % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The precision is: 0.6667\n",
      " The recall is: 0.7500\n"
     ]
    }
   ],
   "source": [
    "print (' The precision is: %.4f' % (precision_score(true_labels, predictions)))\n",
    "\n",
    "print (' The recall is: %.4f' % (recall_score(true_labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 3]\n",
      " [2 6]]\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(true_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My true positive rate is high, which means that when a POI is present in the test data, I am good at flagging him or her."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My identifier doesn’t have great precision, but it does have good recall. That means that, nearly every time a POI shows up in my test set, I am able to identify him or her. The cost of this is that I sometimes get some false positives, where non-POIs get flagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My identifier doesn’t have great recall, but it does have good precision. That means that whenever a POI gets flagged in my test set, I know with a lot of confidence that it’s very likely to be a real POI and not a false alarm. On the other hand, the price I pay for this is that I sometimes miss real POIs, since I’m effectively reluctant to pull the trigger on edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My identifier has a really great F1 score.\n",
    "\n",
    "This is the best of both worlds. Both my false positive and false negative rates are low, which means that I can identify POI’s reliably and accurately. If my identifier finds a POI then the person is almost certainly a POI, and if the identifier does not flag someone, then they are almost certainly not a POI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s usually a tradeoff between precision and recall--which one do you think is more important in your POI identifier? There’s no right or wrong answer, there are good arguments either way, but you should be able to interpret both metrics and articulate which one you find most important and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
